import base64
import configparser
import io
import json
import threading
from pathlib import Path
from typing import List, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed

import numpy as np
import requests
import torch
import urllib3
from PIL import Image, ImageOps

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# çº¿ç¨‹æœ¬åœ°å­˜å‚¨,ç”¨äº Session å¤ç”¨
thread_local = threading.local()

CATEGORY = "artsmcp"
CONFIG_SECTION = "Nano-banana"  # ç‹¬ç«‹é…ç½®èŠ‚
CONFIG_PATH = Path(__file__).parent / "config.ini"
CONFIG = configparser.ConfigParser()
if CONFIG_PATH.exists():
    CONFIG.read(CONFIG_PATH, encoding="utf-8")
else:
    CONFIG[CONFIG_SECTION] = {}  # ä½¿ç”¨ç‹¬ç«‹é…ç½®èŠ‚
    with CONFIG_PATH.open("w", encoding="utf-8") as fp:
        CONFIG.write(fp)

# å®½é«˜æ¯”æ˜ å°„
ASPECT_RATIO_MAP = {
    "1:1": "1:1",
    "4:3": "4:3",
    "3:4": "3:4",
    "16:9": "16:9",
    "9:16": "9:16",
    "2:3": "2:3",
    "3:2": "3:2",
    "4:5": "4:5",
    "5:4": "5:4",
    "21:9": "21:9",
}

# å›¾åƒå°ºå¯¸æ˜ å°„(ä»…nano-banana-2æ”¯æŒ)
IMAGE_SIZE_MAP = {
    "1K": "1K",
    "2K": "2K",
    "4K": "4K",
}

# æ¨¡å‹æ˜ å°„
MODEL_MAP = {
    # "nano-banana": "gemini-2.5-flash-image-preview",
    "nano-banana-2": "nano-banana-2",
    # "gemini-3-pro-image-preview": "gemini-3-pro-image-preview",
}

# å“åº”æ ¼å¼æ˜ å°„
RESPONSE_FORMAT_MAP = {
    "URL": "url",
    "Base64": "b64_json",
}


class ConfigManager:
    """é…ç½®ç®¡ç†å•ä¾‹ç±»"""
    _instance = None
    _config = None
    _config_path = Path(__file__).parent / "config.ini"
    _config_section = "Nano-banana"
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._load_config()
        return cls._instance
    
    @classmethod
    def _load_config(cls):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        cls._config = configparser.ConfigParser()
        if cls._config_path.exists():
            cls._config.read(cls._config_path, encoding="utf-8")
        else:
            cls._config[cls._config_section] = {}
            with cls._config_path.open("w", encoding="utf-8") as fp:
                cls._config.write(fp)
    
    def get_value(self, key, fallback=None):
        """è·å–é…ç½®å€¼"""
        # é‡æ–°è¯»å–é…ç½®æ–‡ä»¶ä»¥ç¡®ä¿è·å–æœ€æ–°å€¼
        self._load_config()
        try:
            return self._config.get(self._config_section, key, fallback=fallback)
        except Exception as e:
            print(f"[CONFIG] è¯»å–é…ç½®å¤±è´¥: {e}")
            return fallback
    
    def set_value(self, key, value):
        """è®¾ç½®é…ç½®å€¼"""
        try:
            if not self._config.has_section(self._config_section):
                self._config.add_section(self._config_section)
            self._config.set(self._config_section, key, value)
            with self._config_path.open("w", encoding="utf-8") as fp:
                self._config.write(fp)
            print(f"[CONFIG] ä¿å­˜ {key} åˆ°é…ç½®æ–‡ä»¶")
        except Exception as e:
            print(f"[ERROR] é…ç½®å†™å…¥å¤±è´¥: {e}")

# å…¨å±€é…ç½®ç®¡ç†å™¨å®ä¾‹
config_manager = ConfigManager()


def get_session():
    """è·å–çº¿ç¨‹æœ¬åœ°çš„ Session (å¤ç”¨è¿æ¥æ± ,ä½¿ç”¨å®˜æ–¹æ¨èçš„ HTTPAdapter é…ç½®)"""
    if not hasattr(thread_local, "session"):
        # åˆ›å»º Session
        session = requests.Session()
        
        # ä½¿ç”¨ HTTPAdapter ç²¾ç»†æ§åˆ¶è¿æ¥æ± 
        adapter = requests.adapters.HTTPAdapter(
            pool_connections=10,  # è¿æ¥æ± æ•°é‡
            pool_maxsize=10,      # æ¯ä¸ªè¿æ¥æ± çš„æœ€å¤§è¿æ¥æ•°
            max_retries=0         # é‡è¯•ç”±ä¸Šå±‚ make_api_request æ§åˆ¶
        )
        
        # æŒ‚è½½åˆ° http å’Œ https
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        
        # å­˜å‚¨åˆ°çº¿ç¨‹æœ¬åœ°
        thread_local.session = session
    
    return thread_local.session


def tensor_to_base64(image_tensor):
    """å°† ComfyUI tensor è½¬æ¢ä¸º base64 å­—ç¬¦ä¸²"""
    if len(image_tensor.shape) > 3:
        image_tensor = image_tensor[0]
    
    array = np.clip(image_tensor.cpu().numpy() * 255.0, 0, 255).astype(np.uint8)
    pil_image = Image.fromarray(array, mode='RGB')
    
    buffered = io.BytesIO()
    pil_image.save(buffered, format="JPEG", quality=95)
    img_bytes = buffered.getvalue()
    base64_string = base64.b64encode(img_bytes).decode('utf-8')
    
    return f"data:image/jpeg;base64,{base64_string}"


def download_image_to_tensor(url: str, timeout: int = 60):
    """ä» URL ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸º tensor"""
    response = None
    
    try:
        print(f"[INFO] æ­£åœ¨ä¸‹è½½å›¾ç‰‡: {url}")
        
        # ä½¿ç”¨çº¿ç¨‹æœ¬åœ° Session (è¿æ¥æ± å¤ç”¨)
        session = get_session()
        response = session.get(url, timeout=timeout, verify=False, stream=True)
        response.raise_for_status()
        
        pil_image = Image.open(io.BytesIO(response.content)).convert('RGB')
        print(f"[INFO] å›¾ç‰‡å°ºå¯¸: {pil_image.size}")
        
        numpy_image = np.array(pil_image).astype(np.float32) / 255.0
        tensor = torch.from_numpy(numpy_image)
        
        return tensor
        
    except Exception as e:
        print(f"[ERROR] ä¸‹è½½å›¾ç‰‡å¤±è´¥: {e}")
        return None
        
    finally:
        # æ¸…ç†èµ„æº (ä½†ä¿ç•™ Session ä¾›çº¿ç¨‹å¤ç”¨)
        try:
            if response is not None:
                response.close()
        except Exception as e:
            print(f"[WARN] æ¸…ç†ä¸‹è½½è¿æ¥å¤±è´¥: {e}")


def base64_to_tensor(b64_string: str):
    """å°† base64 å­—ç¬¦ä¸²è½¬æ¢ä¸º tensor (æ”¯æŒ data URI æ ¼å¼)"""
    try:
        # å¤„ç† data URI æ ¼å¼ (å¦‚: data:image/png;base64,...)
        if b64_string.startswith("data:image"):
            # æå–å®é™…çš„ base64 æ•°æ®éƒ¨åˆ†
            b64_string = b64_string.split(",", 1)[1]
        
        img_bytes = base64.b64decode(b64_string)
        pil_image = Image.open(io.BytesIO(img_bytes)).convert('RGB')
        numpy_image = np.array(pil_image).astype(np.float32) / 255.0
        tensor = torch.from_numpy(numpy_image)
        return tensor
    except Exception as e:
        print(f"[ERROR] Base64 è½¬æ¢å¤±è´¥: {e}")
        return None


def make_api_request(url: str, headers: dict, payload: dict, timeout: int = 120, max_retries: int = 3, backoff: int = 2, verbose: bool = False):
    """å‘é€ API è¯·æ±‚ï¼ˆæ”¯æŒé‡è¯•ï¼‰"""
    import time
    
    # æ‰“å°è¯·æ±‚ä¿¡æ¯
    print(f"[INFO] å‘é€è¯·æ±‚åˆ°: {url}")
    print(f"[INFO] è¯·æ±‚å‚æ•°: {json.dumps(payload, ensure_ascii=False)[:200]}...")
    
    last_error = None
    response = None
    
    for attempt in range(1, max_retries + 1):
        try:
            # æ¸…ç†ä¸Šæ¬¡é‡è¯•çš„ response
            if response is not None:
                response.close()
                response = None
            
            if attempt > 1:
                wait_time = min(backoff ** (attempt - 1), 20)  # æŒ‡æ•°é€€é¿: 2s, 4s, 8s, æœ€å¤§20s
                print(f"[INFO] ç¬¬ {attempt} æ¬¡é‡è¯•ï¼Œç­‰å¾… {wait_time} ç§’...")
                time.sleep(wait_time)
            
            # ä½¿ç”¨çº¿ç¨‹æœ¬åœ° Session (è¿æ¥æ± å¤ç”¨)
            session = get_session()
            response = session.post(
                url,
                headers=headers,
                json=payload,
                timeout=timeout,
                verify=False
            )
            
            # è¯¦ç»†çš„çŠ¶æ€ç å¤„ç†
            print(f"[INFO] HTTP çŠ¶æ€ç : {response.status_code}")
            
            # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
            response.raise_for_status()
            
            # æ‰“å°å“åº”å¤´ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            if verbose:
                print(f"[DEBUG] å“åº” Content-Type: {response.headers.get('Content-Type', 'unknown')}")
                print(f"[DEBUG] å“åº” Content-Length: {response.headers.get('Content-Length', 'unknown')}")
            
            # è·å–åŸå§‹å“åº”æ–‡æœ¬ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            response_text = response.text
            if verbose:
                print(f"[DEBUG] å“åº”åŸå§‹æ–‡æœ¬ï¼ˆå‰500å­—ç¬¦ï¼‰: {response_text[:500]}")
            
            # æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºç©º
            if not response_text or response_text.strip() == "":
                print(f"[ERROR] âŒ API è¿”å›ç©ºå“åº”ï¼")
                print(f"[ERROR] è¿™é€šå¸¸æ„å‘³ç€ API ç«¯ç‚¹é…ç½®é”™è¯¯æˆ– API ä¸æ”¯æŒå½“å‰è¯·æ±‚æ ¼å¼")
                raise ValueError("API è¿”å›ç©ºå“åº”ï¼Œè¯·æ£€æŸ¥ API åœ°å€å’Œè¯·æ±‚æ ¼å¼æ˜¯å¦æ­£ç¡®")
            
            # å°è¯•è§£æ JSON
            try:
                result = response.json()
            except json.JSONDecodeError as e:
                print(f"[ERROR] âŒ JSON è§£æå¤±è´¥: {e}")
                print(f"[ERROR] å“åº”ä¸æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼")
                if verbose:
                    print(f"[DEBUG] å®Œæ•´å“åº”æ–‡æœ¬: {response_text}")
                raise ValueError(f"API è¿”å›çš„å†…å®¹ä¸æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼ï¼Œå“åº”å†…å®¹: {response_text[:200]}...")
            
            print(f"[SUCCESS] è¯·æ±‚æˆåŠŸï¼")
            if verbose:
                print(f"[DEBUG] å®Œæ•´å“åº”æ•°æ®: {json.dumps(result, ensure_ascii=False, indent=2)}")
            
            # æˆåŠŸåå…³é—­ response (ä½†ä¿ç•™ Session)
            response.close()
            return result
            
        except requests.exceptions.HTTPError as exc:
            last_error = exc
            print(f"[ERROR] HTTP é”™è¯¯ (å°è¯• {attempt}/{max_retries}): {exc}")
            
            # æ‰“å°å“åº”å†…å®¹ç”¨äºè°ƒè¯•
            try:
                if response is not None:
                    error_detail = response.json()
                    print(f"[ERROR] é”™è¯¯è¯¦æƒ…: {json.dumps(error_detail, ensure_ascii=False)}")
            except:
                if response is not None:
                    print(f"[ERROR] å“åº”æ–‡æœ¬: {response.text[:500]}")
            
            # 4xx å®¢æˆ·ç«¯é”™è¯¯ç›´æ¥æŠ›å‡ºï¼Œä¸é‡è¯•ï¼ˆé™¤äº† 429 é™æµï¼‰
            if 400 <= exc.response.status_code < 500 and exc.response.status_code != 429:
                print(f"[ERROR] å®¢æˆ·ç«¯é”™è¯¯ ({exc.response.status_code})ï¼Œä¸è¿›è¡Œé‡è¯•")
                # æ¸…ç†èµ„æº
                if response:
                    response.close()
                raise
                
        except requests.exceptions.Timeout as exc:
            last_error = exc
            print(f"[ERROR] è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt}/{max_retries}): {exc}")
            if verbose:
                print(f"[DEBUG] è¶…æ—¶ç±»å‹: {type(exc).__name__}")
            
        except requests.exceptions.ConnectionError as exc:
            last_error = exc
            print(f"[ERROR] è¿æ¥å¤±è´¥ (å°è¯• {attempt}/{max_retries}): {exc}")
            
        except ValueError as exc:
            # JSON è§£æé”™è¯¯æˆ–ç©ºå“åº”ï¼Œä¸åº”è¯¥é‡è¯•
            last_error = exc
            print(f"[ERROR] æ•°æ®æ ¼å¼é”™è¯¯: {exc}")
            print(f"[ERROR] è¿™ä¸æ˜¯ä¸´æ—¶é”™è¯¯ï¼Œåœæ­¢é‡è¯•")
            if response:
                response.close()
            raise
            
        except Exception as exc:
            last_error = exc
            print(f"[ERROR] æœªçŸ¥é”™è¯¯ (å°è¯• {attempt}/{max_retries}): {exc}")
            if verbose:
                print(f"[DEBUG] é”™è¯¯ç±»å‹: {type(exc).__name__}")
                # æ‰“å°å“åº”å†…å®¹ç”¨äºè°ƒè¯•
                if response is not None:
                    try:
                        print(f"[DEBUG] å“åº”çŠ¶æ€ç : {response.status_code}")
                        print(f"[DEBUG] å“åº”å¤´: {dict(response.headers)}")
                        print(f"[DEBUG] å“åº”æ–‡æœ¬: {response.text[:500]}")
                    except:
                        pass
        
        finally:
            # ç¡®ä¿ response è¢«å…³é—­ (ä½†ä¿ç•™çº¿ç¨‹æœ¬åœ° Session)
            try:
                if response is not None:
                    response.close()
            except Exception as e:
                print(f"[WARN] æ¸…ç†è¿æ¥å¤±è´¥: {e}")
        
        # å¦‚æœè¿˜æœ‰é‡è¯•æœºä¼šï¼Œç»§ç»­å¾ªç¯
        if attempt < max_retries:
            continue
    
    # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
    print(f"\n[ERROR] âŒ è¯·æ±‚æœ€ç»ˆå¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡")
    print(f"[ERROR] æœ€åé”™è¯¯: {last_error}")
    print(f"\nğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
    print(f"   1. æ£€æŸ¥ API æœåŠ¡æ˜¯å¦æ­£å¸¸: {url}")
    print(f"   2. ç¡®è®¤ API Key æ˜¯å¦æœ‰æ•ˆ")
    print(f"   3. ç¨åå†è¯•ï¼Œå¯èƒ½æ˜¯æœåŠ¡å™¨ä¸´æ—¶è¿‡è½½")
    print(f"   4. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦ç¨³å®š")
    print(f"   5. å°è¯•å¢åŠ  timeout å‚æ•°å€¼")
    
    if last_error:
        raise last_error
    raise RuntimeError("æœªçŸ¥è¯·æ±‚å¤±è´¥")


class NanoBananaNode:
    """Nano Banana å›¾ç‰‡ç”ŸæˆèŠ‚ç‚¹ - æ”¯æŒæ–‡ç”Ÿå›¾ã€å›¾ç”Ÿå›¾ã€å¤šå›¾èåˆ"""
    
    def __init__(self):
        self.verbose = False  # é»˜è®¤å…³é—­è¯¦ç»†æ—¥å¿—
    
    def log(self, message, level="INFO"):
        """ç»Ÿä¸€æ—¥å¿—è¾“å‡º (æ”¯æŒåˆ†çº§)"""
        if level == "DEBUG" and not self.verbose:
            return  # DEBUG æ—¥å¿—åªåœ¨ verbose æ¨¡å¼ä¸‹æ‰“å°
        print(message)
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "æç¤ºè¯": ("STRING", {
                    "multiline": True,
                    "default": "ä¸€åªå¯çˆ±çš„çŒ«å’ª,å¡é€šé£æ ¼,é«˜æ¸…",
                    "label": "ğŸ’¬ æç¤ºè¯"
                }),
                "APIå¯†é’¥": ("STRING", {
                    "multiline": False,
                    "default": CONFIG.get(CONFIG_SECTION, "api_key", fallback=CONFIG.get("DEFAULT", "api_key", fallback="")),
                    "label": "ğŸ”‘ APIå¯†é’¥"
                }),
                "APIåœ°å€": ("STRING", {
                    "multiline": False,
                    "default": CONFIG.get(CONFIG_SECTION, "api_url", fallback=CONFIG.get("DEFAULT", "api_url", fallback="https://api.openai.com")),
                    "label": "ğŸŒ APIåœ°å€"
                }),
                "æ¨¡å‹": (list(MODEL_MAP.keys()), {
                    "default": list(MODEL_MAP.keys())[0],
                    "label": "ğŸ§  æ¨¡å‹"
                }),
                "å®½é«˜æ¯”": (list(ASPECT_RATIO_MAP.keys()), {
                    "default": "1:1",
                    "label": "ğŸ“ å°ºå¯¸æ¯”ä¾‹(size)"
                }),
                "åˆ†è¾¨ç‡": (list(IMAGE_SIZE_MAP.keys()) + ["none"], {
                    "default": "2K",
                    "label": "ğŸ“ åˆ†è¾¨ç‡"
                }),
                # å“åº”æ ¼å¼æš‚æ—¶å†™æ­»ä¸º Base64
                # "å“åº”æ ¼å¼": (list(RESPONSE_FORMAT_MAP.keys()), {
                #     "default": "URL",
                #     "label": "ğŸ“¦ å“åº”æ ¼å¼"
                # }),
                "è¶…æ—¶ç§’æ•°": ("INT", {
                    "default": 120,
                    "min": 30,
                    "max": 600,
                    "step": 10,
                    "label": "â±ï¸ è¶…æ—¶(ç§’)"
                }),
                "æœ€å¤§é‡è¯•æ¬¡æ•°": ("INT", {
                    "default": 3,
                    "min": 1,
                    "max": 10,
                    "step": 1,
                    "label": "ğŸ”„ æœ€å¤§é‡è¯•æ¬¡æ•°"
                }),
                "å¹¶å‘è¯·æ±‚æ•°": ("INT", {
                    "default": 1,
                    "min": 1,
                    "max": 10,
                    "step": 1,
                    "label": "ğŸ“Š å¹¶å‘è¯·æ±‚æ•°"
                }),
                "å¯ç”¨åˆ†è¡Œæç¤ºè¯": ("BOOLEAN", {
                    "default": False,
                    "label": "ğŸ“ å¯ç”¨åˆ†è¡Œæç¤ºè¯"
                }),
                "åŒ¹é…å‚è€ƒå°ºå¯¸": ("BOOLEAN", {
                    "default": False,
                    "label": "ğŸ“¸ åŒ¹é…å‚è€ƒå°ºå¯¸",
                    "label_on": "å¼€å¯",
                    "label_off": "å…³é—­"
                }),
                "è¯¦ç»†æ—¥å¿—": ("BOOLEAN", {
                    "default": False,
                    "label": "ğŸ” è¯¦ç»†æ—¥å¿—"
                }),
            },
            "optional": {
                "å‚è€ƒå›¾ç‰‡1": ("IMAGE", {"label": "ğŸ–¼ï¸ å‚è€ƒå›¾ç‰‡1"}),
                "å‚è€ƒå›¾ç‰‡2": ("IMAGE", {"label": "ğŸ–¼ï¸ å‚è€ƒå›¾ç‰‡2"}),
                "å‚è€ƒå›¾ç‰‡3": ("IMAGE", {"label": "ğŸ–¼ï¸ å‚è€ƒå›¾ç‰‡3"}),
                "å‚è€ƒå›¾ç‰‡4": ("IMAGE", {"label": "ğŸ–¼ï¸ å‚è€ƒå›¾ç‰‡4"}),
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("å›¾ç‰‡è¾“å‡º",)
    FUNCTION = "generate_image"
    CATEGORY = CATEGORY
    OUTPUT_NODE = False  # æ ‡æ˜è¿™ä¸æ˜¯è¾“å‡ºèŠ‚ç‚¹
    
    @classmethod
    def IS_CHANGED(cls, **kwargs):
        """å¼ºåˆ¶æ¯æ¬¡éƒ½é‡æ–°æ‰§è¡Œ,ä¸ä½¿ç”¨ç¼“å­˜(å› ä¸ºæ˜¯å¤–éƒ¨APIè¯·æ±‚)"""
        import time
        return time.time()
    
    def generate_image(self, æç¤ºè¯, APIå¯†é’¥, APIåœ°å€, æ¨¡å‹, å®½é«˜æ¯”, åˆ†è¾¨ç‡, 
                       è¶…æ—¶ç§’æ•°, æœ€å¤§é‡è¯•æ¬¡æ•°, å¹¶å‘è¯·æ±‚æ•°, å¯ç”¨åˆ†è¡Œæç¤ºè¯, åŒ¹é…å‚è€ƒå°ºå¯¸, è¯¦ç»†æ—¥å¿—,
                       å‚è€ƒå›¾ç‰‡1=None, å‚è€ƒå›¾ç‰‡2=None, å‚è€ƒå›¾ç‰‡3=None, å‚è€ƒå›¾ç‰‡4=None):
        """ä¸»ç”Ÿæˆå‡½æ•° - é‡æ„ä¸ºæ¸…æ™°çš„æµç¨‹"""
        
        # è®¾ç½®æ—¥å¿—çº§åˆ«
        self.verbose = è¯¦ç»†æ—¥å¿—
        
        # å†™æ­»å“åº”æ ¼å¼ä¸º Base64
        response_format = "Base64"
        
        # ä¿å­˜é…ç½®åˆ°ç‹¬ç«‹é…ç½®èŠ‚ï¼ˆæ¯æ¬¡é‡æ–°è¯»å–ç¡®ä¿æ•°æ®æœ€æ–°ï¼‰
        config_writer = configparser.ConfigParser()
        if CONFIG_PATH.exists():
            config_writer.read(CONFIG_PATH, encoding="utf-8")
        
        if not config_writer.has_section(CONFIG_SECTION):
            config_writer.add_section(CONFIG_SECTION)
        
        # åªä¿å­˜éç©ºçš„é…ç½®é¡¹
        if APIå¯†é’¥.strip():
            config_writer.set(CONFIG_SECTION, "api_key", APIå¯†é’¥.strip())
            print(f"[CONFIG] ä¿å­˜ api_key åˆ°é…ç½®æ–‡ä»¶")
        if APIåœ°å€.strip():
            config_writer.set(CONFIG_SECTION, "api_url", APIåœ°å€.strip())
            print(f"[CONFIG] ä¿å­˜ api_url åˆ°é…ç½®æ–‡ä»¶: {APIåœ°å€.strip()}")
        
        try:
            with CONFIG_PATH.open("w", encoding="utf-8") as fp:
                config_writer.write(fp)
            print(f"[CONFIG] é…ç½®å·²æˆåŠŸå†™å…¥: {CONFIG_PATH}")
        except Exception as e:
            print(f"[ERROR] é…ç½®å†™å…¥å¤±è´¥: {e}")
        
        # æ‰“å°è¾“å…¥å‚æ•°ï¼ˆè°ƒè¯•ç”¨ï¼‰
        print("\n" + "="*60)
        print("[Nano-Banana] è¾“å…¥å‚æ•°:")
        print(f"  - æç¤ºè¯: {æç¤ºè¯[:50]}...")
        print(f"  - æ¨¡å‹: {æ¨¡å‹}")
        print(f"  - å®½é«˜æ¯”: {å®½é«˜æ¯”}")
        print(f"  - åˆ†è¾¨ç‡: {åˆ†è¾¨ç‡}")
        print(f"  - å“åº”æ ¼å¼: {response_format}")
        print(f"  - å¹¶å‘è¯·æ±‚æ•°: {å¹¶å‘è¯·æ±‚æ•°}")
        print("="*60 + "\n")
        
        # æ”¶é›†è¾“å…¥å›¾ç‰‡
        input_images = []
        for idx, img in enumerate([å‚è€ƒå›¾ç‰‡1, å‚è€ƒå›¾ç‰‡2, å‚è€ƒå›¾ç‰‡3, å‚è€ƒå›¾ç‰‡4], 1):
            if img is not None:
                input_images.append(img)
                self.log(f"[DEBUG] æ£€æµ‹åˆ°å‚è€ƒå›¾ç‰‡{idx}, å½¢çŠ¶: {img.shape}", "DEBUG")
        
        self.log(f"[DEBUG] å…±æ”¶é›†åˆ° {len(input_images)} å¼ å‚è€ƒå›¾ç‰‡", "DEBUG")
        
        # æŒ‰ Gemini demo æ„å»ºè¯·æ±‚å‚æ•°ï¼ˆcontents + parts + inline_dataï¼‰
        model_value = MODEL_MAP[æ¨¡å‹]
        size_value = ASPECT_RATIO_MAP[å®½é«˜æ¯”]  # ä»…ç”¨äºæ—¥å¿—
        response_format_value = RESPONSE_FORMAT_MAP[response_format]
        
        # ç»„è£…æç¤ºè¯
        if å¯ç”¨åˆ†è¡Œæç¤ºè¯:
            # æ¯ä¸€è¡Œä½œä¸ºä¸€ä¸ªç‹¬ç«‹çš„æç¤ºè¯ï¼Œåˆ†åˆ«ç”Ÿæˆå›¾ç‰‡
            prompt_lines = [line.strip() for line in æç¤ºè¯.split('\n') if line.strip()]
            print(f"[INFO] å¯ç”¨åˆ†è¡Œæç¤ºè¯ï¼Œå…± {len(prompt_lines)} è¡Œ")
            print(f"[INFO] æ¯è¡Œå°†å„å‘é€ {å¹¶å‘è¯·æ±‚æ•°} ä¸ªè¯·æ±‚ï¼Œæ€»è®¡: {len(prompt_lines) * å¹¶å‘è¯·æ±‚æ•°} ä¸ªè¯·æ±‚")
            self.log(f"[DEBUG] åˆ†è¡Œæç¤ºè¯å†…å®¹: {prompt_lines}", "DEBUG")
        else:
            # å•è¡Œæç¤ºè¯
            prompt_lines = [æç¤ºè¯]
        
        # æ ¹æ®æ˜¯å¦å¯ç”¨åˆ†è¡Œæç¤ºè¯ï¼Œå‡†å¤‡ä¸åŒçš„ payload åˆ—è¡¨
        payload_list = []
        
        for line_idx, prompt_text in enumerate(prompt_lines, 1):
            # ä¸ºæ¯ä¸€è¡Œæç¤ºè¯æ„å»ºç‹¬ç«‹çš„ payload
            contents_parts = [
                {"text": prompt_text}
            ]
            
            # å¤„ç†è¾“å…¥å›¾ç‰‡ï¼ˆå›¾ç”Ÿå›¾/å¤šå›¾èåˆæ¨¡å¼ï¼‰
            if input_images:
                print(f"[INFO] æ£€æµ‹åˆ° {len(input_images)} å¼ å‚è€ƒå›¾ç‰‡ï¼Œå¯ç”¨å¤šå›¾èåˆæ¨¡å¼")
                # å°†æ‰€æœ‰å‚è€ƒå›¾ç‰‡éƒ½æ·»åŠ åˆ° parts æ•°ç»„ä¸­
                for img_idx, img_tensor in enumerate(input_images, 1):
                    base64_image = tensor_to_base64(img_tensor)
                    # tensor_to_base64 è¿”å› data URIï¼Œéœ€è¦æå–é€—å·åé¢çš„çº¯ Base64 æ•°æ®
                    if isinstance(base64_image, str) and base64_image.startswith("data:image"):
                        base64_image = base64_image.split(",", 1)[1]
                    
                    contents_parts.append(
                        {
                            "inline_data": {
                                "mime_type": "image/jpeg",
                                "data": base64_image
                            }
                        }
                    )
                    print(f"[INFO] å·²æ·»åŠ å‚è€ƒå›¾ç‰‡ {img_idx}/{len(input_images)} åˆ° parts æ•°ç»„")
            
            # æ„å»º Gemini åŸç”Ÿè¯·æ±‚ä½“
            payload = {
                "contents": [
                    {
                        "parts": contents_parts
                    }
                ]
            }

            # æ ¹æ®æ¨¡å‹å’ŒèŠ‚ç‚¹å‚æ•°ï¼ŒæŒ‰éœ€æ³¨å…¥å°ºå¯¸ / æ¯”ä¾‹é…ç½®
            # ä»…å½“ç¡®å®è®¾ç½®äº†ç›¸å…³å‚æ•°æ—¶æ‰å†™å…¥ payloadï¼Œé¿å…è§¦å‘æ— æ•ˆå‚æ•°é”™è¯¯
            image_config = {}

            # åˆ†è¾¨ç‡ï¼ˆåŸå›¾åƒå°ºå¯¸ï¼‰
            if åˆ†è¾¨ç‡ and åˆ†è¾¨ç‡ != "none":
                image_size_value = IMAGE_SIZE_MAP.get(åˆ†è¾¨ç‡)
                if image_size_value:
                    image_config["imageSize"] = image_size_value

            # å®½é«˜æ¯”: å§‹ç»ˆæ³¨å…¥ï¼ˆæ–‡ç”Ÿå›¾å’Œå›¾ç”Ÿå›¾æ¨¡å¼éƒ½æ”¯æŒï¼‰
            if å®½é«˜æ¯” in ASPECT_RATIO_MAP:
                aspect_ratio_value = ASPECT_RATIO_MAP[å®½é«˜æ¯”]
                if aspect_ratio_value:
                    image_config["aspectRatio"] = aspect_ratio_value

            if image_config:
                payload["generationConfig"] = {
                    "imageConfig": image_config
                }
            
            # æ¯ä¸ª prompt éƒ½å‘é€ N æ¬¡è¯·æ±‚ï¼ˆN = å¹¶å‘è¯·æ±‚æ•°ï¼‰
            for _ in range(å¹¶å‘è¯·æ±‚æ•°):
                payload_list.append((line_idx, prompt_text, payload.copy()))
        
        # æ‰“å°æ¨¡å¼ä¿¡æ¯
        if input_images:
            print(f"[INFO] æ¨¡å¼: å›¾ç”Ÿå›¾ï¼ˆå‚è€ƒå›¾æ•°é‡: {len(input_images)}ï¼‰")
        else:
            print("[INFO] æ¨¡å¼: æ–‡ç”Ÿå›¾ï¼ˆä»…æ–‡æœ¬æç¤ºè¯ï¼‰")
        
        self.log(f"[DEBUG] æœ€ç»ˆ payload é¡¶å±‚å­—æ®µ: {list(payload_list[0][2].keys())}", "DEBUG")
        self.log(f"[DEBUG] æ¨¡å‹: {model_value}, å®½é«˜æ¯”(ä»…æ—¥å¿—): {size_value}", "DEBUG")
        
        # æŒ‰ Gemini demo æ„å»ºå®Œæ•´ URL:
        # {base_url}/v1beta/models/{model}:generateContent?key={APIå¯†é’¥}
        base_url = APIåœ°å€.strip()
        if not base_url:
            base_url = "https://api.openai.com"
        
        if not (base_url.startswith("http://") or base_url.startswith("https://")):
            base_url = "https://" + base_url
        
        base_url = base_url.rstrip("/")
        final_url = f"{base_url}/v1beta/models/{model_value}:generateContent?key={APIå¯†é’¥.strip()}"
        
        print(f"[INFO] è§£æåçš„å®Œæ•´ API åœ°å€: {final_url}")
        
        # å‘é€è¯·æ±‚ï¼ˆé‰´æƒé€šè¿‡ URL ä¸­çš„ keyï¼ŒHeader åªéœ€è¦ Content-Typeï¼‰
        headers = {
            "Content-Type": "application/json"
        }
        
        # æ‰“å°å®Œæ•´çš„payloadç”¨äºè°ƒè¯•ï¼ˆåªæ‰“å°ç¬¬ä¸€ä¸ªï¼‰
        if payload_list and self.verbose:
            self.log(f"[DEBUG] å®Œæ•´ payload ç»“æ„ï¼ˆç¤ºä¾‹ï¼‰:", "DEBUG")
            try:
                self.log(json.dumps(payload_list[0][2], ensure_ascii=False)[:500] + "...", "DEBUG")
            except Exception as e:
                print(f"[WARN] payload åºåˆ—åŒ–å¤±è´¥: {e}")
        
        try:
            # å¹¶å‘å‘é€è¯·æ±‚ï¼ˆæ”¯æŒåˆ†è¡Œæç¤ºè¯ + ç”Ÿå›¾æ•°é‡ï¼‰
            total_requests = len(payload_list)
            print(f"\n{'='*60}")
            print(f"[INFO] å¼€å§‹å¹¶å‘ç”Ÿæˆ {total_requests} å¼ å›¾ç‰‡...")
            print(f"[INFO] å¹¶å‘çº¿ç¨‹æ•°: {min(total_requests, 5)}")
            print(f"{'='*60}\n")
            
            results = []
            with ThreadPoolExecutor(max_workers=min(total_requests, 5)) as executor:
                # æäº¤æ‰€æœ‰è¯·æ±‚ä»»åŠ¡
                futures = [
                    executor.submit(
                        make_api_request, 
                        final_url, 
                        headers, 
                        payload_data,  # å·²ç»æ˜¯å‰¯æœ¬
                        è¶…æ—¶ç§’æ•°, 
                        æœ€å¤§é‡è¯•æ¬¡æ•°,
                        2,  # backoff
                        è¯¦ç»†æ—¥å¿—  # ä¼ é€’ verbose å‚æ•°
                    ) 
                    for line_idx, prompt_text, payload_data in payload_list
                ]
                
                # ç­‰å¾…æ‰€æœ‰è¯·æ±‚å®Œæˆå¹¶æ”¶é›†ç»“æœ
                for idx, future in enumerate(as_completed(futures), 1):
                    try:
                        result = future.result()
                        results.append(result)
                        print(f"[INFO] âœ… ç¬¬ {idx}/{total_requests} ä¸ªè¯·æ±‚å·²å®Œæˆ")
                    except Exception as e:
                        print(f"[ERROR] âŒ ç¬¬ {idx}/{total_requests} ä¸ªè¯·æ±‚å¤±è´¥: {e}")
                        # ç»§ç»­å¤„ç†å…¶ä»–è¯·æ±‚ï¼Œä¸ä¸­æ–­
            
            # æ£€æŸ¥æ˜¯å¦è‡³å°‘æœ‰ä¸€ä¸ªæˆåŠŸçš„ç»“æœ
            if not results:
                raise RuntimeError(f"æ‰€æœ‰ {total_requests} ä¸ªè¯·æ±‚å‡å¤±è´¥ï¼Œæœªè·å–åˆ°ä»»ä½•å›¾ç‰‡æ•°æ®")
            
            print(f"\n{'='*60}")
            print(f"[SUCCESS] âœ… å¹¶å‘è¯·æ±‚å®Œæˆï¼")
            print(f"[INFO] æˆåŠŸ: {len(results)}/{total_requests} ä¸ªè¯·æ±‚")
            if len(results) < total_requests:
                print(f"[WARN] âš ï¸ éƒ¨åˆ†è¯·æ±‚å¤±è´¥ï¼Œä»…è¿”å›æˆåŠŸçš„å›¾ç‰‡")
            print(f"{'='*60}\n")
            
            # è§£ææ‰€æœ‰å“åº”å¹¶åˆå¹¶è¾“å‡º
            output_tensors = []
            
            # éå†æ‰€æœ‰è¯·æ±‚çš„å“åº”ç»“æœ
            for result_idx, result in enumerate(results, 1):
                self.log(f"\n[DEBUG] ===== å¤„ç†ç¬¬ {result_idx}/{len(results)} ä¸ªå“åº” =====", "DEBUG")
                self.log(f"[DEBUG] å“åº”åŒ…å«çš„é”®: {list(result.keys())}", "DEBUG")
                
                # ä¼˜å…ˆå¤„ç† Gemini åŸç”Ÿæ ¼å¼: candidates -> content.parts
                if "candidates" in result:
                    candidates = result.get("candidates", [])
                    self.log(f"[DEBUG] æ£€æµ‹åˆ° Gemini å“åº”æ ¼å¼ï¼Œcandidates æ•°é‡: {len(candidates)}", "DEBUG")
                    
                    for c_idx, candidate in enumerate(candidates):
                        content = candidate.get("content", {})
                        parts = content.get("parts", [])
                        self.log(f"[DEBUG] å¤„ç†ç¬¬ {c_idx+1} ä¸ª candidateï¼Œparts æ•°é‡: {len(parts)}", "DEBUG")
                        
                        for p_idx, part in enumerate(parts):
                            self.log(f"[DEBUG] å¤„ç†ç¬¬ {c_idx+1} ä¸ª candidate çš„ç¬¬ {p_idx+1} ä¸ª partï¼Œkeys: {list(part.keys())}", "DEBUG")
                            # 1. inlineData / inline_dataï¼ˆä¼˜å…ˆå›¾ç‰‡ï¼‰
                            inline_data = part.get("inlineData") or part.get("inline_data")
                            if inline_data:
                                img_b64 = inline_data.get("data")
                                if img_b64:
                                    self.log(f"[DEBUG] ä» inline_data ä¸­æå–åˆ°å›¾ç‰‡ Base64ï¼Œé•¿åº¦: {len(img_b64)}", "DEBUG")
                                    tensor = base64_to_tensor(img_b64)
                                    if tensor is not None:
                                        output_tensors.append(tensor)
                                        self.log(f"[DEBUG] âœ… ç¬¬ {len(output_tensors)} å¼ å›¾ç‰‡è§£ç æˆåŠŸï¼ˆæ¥è‡ªå“åº” {result_idx}ï¼‰", "DEBUG")
                                    else:
                                        self.log("[DEBUG] âŒ å›¾ç‰‡ Base64 è§£ç å¤±è´¥", "DEBUG")
                            # 2. æ–‡æœ¬é‡Œå¯èƒ½å¡äº† data:image/base64,...
                            elif "text" in part:
                                text_content = part["text"]
                                self.log(f"[DEBUG] æ–‡æœ¬ part å†…å®¹: {text_content[:100]}...", "DEBUG")
                                if "data:image" in text_content and "base64," in text_content:
                                    try:
                                        b64_part = text_content.split("base64,")[-1].strip()
                                        b64_part = b64_part.replace(")", "").replace("]", "")
                                        tensor = base64_to_tensor(b64_part)
                                        if tensor is not None:
                                            output_tensors.append(tensor)
                                            self.log(f"[DEBUG] âœ… ä»æ–‡æœ¬ä¸­æå–å›¾ç‰‡ Base64 å¹¶è§£ç æˆåŠŸï¼Œå½“å‰æ€»æ•°: {len(output_tensors)}", "DEBUG")
                                    except Exception as e:
                                        print(f"[WARN] ä»æ–‡æœ¬æå–å›¾ç‰‡ Base64 å¤±è´¥: {e}")
                # å…¼å®¹æ—§çš„ OpenAI images/generations é£æ ¼: data + b64_json/url
                elif "data" in result:
                    data = result["data"]
                    self.log(f"[DEBUG] data ç±»å‹: {type(data)}", "DEBUG")
                    
                    if isinstance(data, list):
                        self.log(f"[DEBUG] data æ˜¯åˆ—è¡¨ï¼Œé•¿åº¦: {len(data)}", "DEBUG")
                        for idx, item in enumerate(data):
                            self.log(f"[DEBUG] å¤„ç†ç¬¬ {idx+1} ä¸ªå›¾ç‰‡é¡¹ï¼ˆæ¥è‡ªå“åº” {result_idx}ï¼‰...", "DEBUG")
                            self.log(f"[DEBUG] å›¾ç‰‡é¡¹åŒ…å«çš„é”®: {list(item.keys()) if isinstance(item, dict) else 'N/A'}", "DEBUG")
                            
                            tensor = self._process_image_item(item, response_format_value, è¶…æ—¶ç§’æ•°)
                            if tensor is not None:
                                output_tensors.append(tensor)
                                self.log(f"[DEBUG] âœ… ç¬¬ {len(output_tensors)} å¼ å›¾ç‰‡è½¬æ¢æˆåŠŸ", "DEBUG")
                            else:
                                self.log(f"[DEBUG] âŒ å›¾ç‰‡è½¬æ¢å¤±è´¥", "DEBUG")
                                
                    elif isinstance(data, dict):
                        self.log(f"[DEBUG] data æ˜¯å­—å…¸", "DEBUG")
                        self.log(f"[DEBUG] å­—å…¸åŒ…å«çš„é”®: {list(data.keys())}", "DEBUG")
                        
                        tensor = self._process_image_item(data, response_format_value, è¶…æ—¶ç§’æ•°)
                        if tensor is not None:
                            output_tensors.append(tensor)
                            self.log(f"[DEBUG] âœ… å›¾ç‰‡è½¬æ¢æˆåŠŸï¼ˆæ¥è‡ªå“åº” {result_idx}ï¼‰", "DEBUG")
                        else:
                            self.log(f"[DEBUG] âŒ å›¾ç‰‡è½¬æ¢å¤±è´¥", "DEBUG")
                else:
                    print(f"[ERROR] å“åº” {result_idx} ä¸­æ—¢æ²¡æœ‰ 'candidates' ä¹Ÿæ²¡æœ‰ 'data' å­—æ®µï¼")
                    self.log(f"[DEBUG] å®Œæ•´å“åº”å†…å®¹: {result}", "DEBUG")
            
            if not output_tensors:
                print("[ERROR] âŒ æœªè·å–åˆ°ä»»ä½•å›¾ç‰‡æ•°æ®ï¼")
                self.log(f"[DEBUG] è¾“å‡º tensors æ•°é‡: {len(output_tensors)}", "DEBUG")
                # ç›´æ¥æŠ›å‡ºå¼‚å¸¸ï¼Œä¸è¿”å›é»˜è®¤å›¾ç‰‡
                raise RuntimeError("æœªè·å–åˆ°ä»»ä½•å›¾ç‰‡æ•°æ®")
            
            # å¦‚æœå¯ç”¨"åŒ¹é…å‚è€ƒå°ºå¯¸"ä¸”æœ‰å‚è€ƒå›¾ç‰‡ï¼Œåˆ™è°ƒæ•´è¾“å‡ºå°ºå¯¸
            if åŒ¹é…å‚è€ƒå°ºå¯¸ and input_images:
                output_tensors = self._match_reference_size(output_tensors, input_images)
            
            # å½’ä¸€åŒ–tensorå°ºå¯¸(é˜²æ­¢å°ºå¯¸ä¸ä¸€è‡´å¯¼è‡´stackå´©æºƒ)
            output_tensors = self._normalize_tensor_size(output_tensors)
            
            # åˆå¹¶æ‰€æœ‰ tensor
            batch_tensor = torch.stack(output_tensors, dim=0).contiguous()
            print(f"\n{'='*60}")
            print(f"[SUCCESS] âœ… æˆåŠŸç”Ÿæˆ {len(output_tensors)} å¼ å›¾ç‰‡!")
            print(f"[INFO] æ‰¹æ¬¡å°ºå¯¸: {batch_tensor.shape}")
            print(f"{'='*60}\n")
            
            self.log(f"[DEBUG] å‡†å¤‡è¿”å› tensorï¼Œç¡®ä¿æ•°æ®å®Œæ•´æ€§...", "DEBUG")
            self.log(f"[DEBUG] tensor ç±»å‹: {type(batch_tensor)}", "DEBUG")
            self.log(f"[DEBUG] tensor device: {batch_tensor.device}", "DEBUG")
            self.log(f"[DEBUG] tensor dtype: {batch_tensor.dtype}", "DEBUG")
            
            if self.verbose:
                print(f"\n{'='*60}")
                print(f"[OUTPUT] å‡†å¤‡ä¼ é€’ç»™ä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„æ•°æ®è¯¦æƒ…:")
                print(f"{'='*60}")
                print(f"[OUTPUT] æ•°æ®ç±»å‹: {type(batch_tensor).__name__}")
                print(f"[OUTPUT] æ•°æ®å½¢çŠ¶ (shape): {batch_tensor.shape}")
                print(f"  â”œâ”€ æ‰¹æ¬¡å¤§å° (batch): {batch_tensor.shape[0]}")
                print(f"  â”œâ”€ å›¾ç‰‡é«˜åº¦ (height): {batch_tensor.shape[1]}")
                print(f"  â”œâ”€ å›¾ç‰‡å®½åº¦ (width): {batch_tensor.shape[2]}")
                print(f"  â””â”€ é€šé“æ•° (channels): {batch_tensor.shape[3]}")
                print(f"[OUTPUT] æ•°æ®ç»´åº¦ (ndim): {batch_tensor.ndim}")
                print(f"[OUTPUT] å…ƒç´ æ€»æ•°: {batch_tensor.numel():,}")
                print(f"[OUTPUT] æ•°æ®ç±»å‹ (dtype): {batch_tensor.dtype}")
                print(f"[OUTPUT] å­˜å‚¨è®¾å¤‡ (device): {batch_tensor.device}")
                print(f"[OUTPUT] æ˜¯å¦éœ€è¦æ¢¯åº¦: {batch_tensor.requires_grad}")
                print(f"[OUTPUT] å†…å­˜å¤§å°: {batch_tensor.element_size() * batch_tensor.numel() / 1024 / 1024:.2f} MB")
                print(f"[OUTPUT] æ•°å€¼èŒƒå›´: [{batch_tensor.min():.4f}, {batch_tensor.max():.4f}]")
                print(f"[OUTPUT] æ•°å€¼å‡å€¼: {batch_tensor.mean():.4f}")
                print(f"[OUTPUT] æ•°å€¼æ ‡å‡†å·®: {batch_tensor.std():.4f}")
                print(f"\n[OUTPUT] è¿”å›å€¼ç»“æ„: tuple åŒ…å« 1 ä¸ªå…ƒç´ ")
                print(f"[OUTPUT] è¿”å›å€¼å†…å®¹: (torch.Tensor,)")
                print(f"[OUTPUT] ComfyUI å°†æ¥æ”¶åˆ°ç±»å‹ä¸º 'IMAGE' çš„è¾“å‡º")
                print(f"{'='*60}\n")
            
            print(f"[INFO] âœ… èŠ‚ç‚¹æ‰§è¡Œå®Œæ¯•ï¼Œè¿”å›ç»“æœ")
            return (batch_tensor,)
            
        except InterruptedError as e:
            # ç”¨æˆ·ä¸»åŠ¨ä¸­æ–­
            print(f"[INFO] â„¹ï¸ ç”¨æˆ·å·²ä¸­æ–­ç”Ÿæˆä»»åŠ¡")
            raise e
            
        except Exception as e:
            # æ‰€æœ‰å¼‚å¸¸ç»Ÿä¸€å¤„ç†
            print(f"[ERROR] ç”Ÿæˆå¤±è´¥: {e}")
            self.log(f"[DEBUG] å¼‚å¸¸ç±»å‹: {type(e).__name__}", "DEBUG")
            import traceback
            traceback.print_exc()
            raise
    
    def _process_image_item(self, item: dict, format_type: str, timeout: int):
        """å¤„ç†å•ä¸ªå›¾ç‰‡æ•°æ®é¡¹"""
        self.log(f"[DEBUG] _process_image_item è°ƒç”¨: format_type={format_type}", "DEBUG")
        self.log(f"[DEBUG] item å†…å®¹: {item}", "DEBUG")
        
        if format_type == "url" and "url" in item:
            self.log(f"[DEBUG] åŒ¹é…åˆ° URL æ ¼å¼ï¼Œå¼€å§‹ä¸‹è½½...", "DEBUG")
            return download_image_to_tensor(item["url"], timeout)
        elif format_type == "b64_json" and "b64_json" in item:
            self.log(f"[DEBUG] åŒ¹é…åˆ° Base64 æ ¼å¼ï¼Œå¼€å§‹è§£ç ...", "DEBUG")
            return base64_to_tensor(item["b64_json"])
        else:
            print(f"[ERROR] æœªåŒ¹é…åˆ°ä»»ä½•æ ¼å¼ï¼")
            self.log(f"[DEBUG] æœŸæœ›æ ¼å¼: {format_type}", "DEBUG")
            self.log(f"[DEBUG] item åŒ…å«çš„é”®: {list(item.keys()) if isinstance(item, dict) else 'N/A'}", "DEBUG")
            return None
    
    def _normalize_tensor_size(self, tensors):
        """å½’ä¸€åŒ–tensorå°ºå¯¸,é¿å…å°ºå¯¸ä¸ä¸€è‡´å¯¼è‡´stackå´©æºƒ"""
        if not tensors:
            return tensors
        
        # è·å–æ‰€æœ‰tensorçš„å°ºå¯¸
        shapes = [(t.shape[0], t.shape[1]) for t in tensors]
        heights = [s[0] for s in shapes]
        widths = [s[1] for s in shapes]
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å°ºå¯¸éƒ½ä¸€è‡´
        if len(set(shapes)) == 1:
            self.log(f"[DEBUG] æ‰€æœ‰å›¾ç‰‡å°ºå¯¸ä¸€è‡´: {shapes[0]}", "DEBUG")
            return tensors
        
        # å°ºå¯¸ä¸ä¸€è‡´,éœ€è¦å½’ä¸€åŒ–
        print(f"[WARN] âš ï¸ æ£€æµ‹åˆ°å›¾ç‰‡å°ºå¯¸ä¸ä¸€è‡´!")
        print(f"[WARN] å°ºå¯¸åˆ†å¸ƒ: {set(shapes)}")
        
        # ä½¿ç”¨æœ€å°å…¬å…±å°ºå¯¸(è£å‰ªç­–ç•¥)
        min_h = min(heights)
        min_w = min(widths)
        
        print(f"[INFO] ç»Ÿä¸€è£å‰ªåˆ°æœ€å°å…¬å…±å°ºå¯¸: {min_h}Ã—{min_w}")
        
        # ä¸­å¿ƒè£å‰ª
        normalized = []
        for idx, t in enumerate(tensors):
            h, w, c = t.shape
            
            # è®¡ç®—è£å‰ªèµ·å§‹ä½ç½®(ä¸­å¿ƒå¯¹é½)
            start_h = (h - min_h) // 2
            start_w = (w - min_w) // 2
            
            # è£å‰ª
            cropped = t[start_h:start_h+min_h, start_w:start_w+min_w, :]
            normalized.append(cropped)
            
            if h != min_h or w != min_w:
                self.log(f"[DEBUG] å›¾ç‰‡{idx+1}: {h}Ã—{w} â†’ {min_h}Ã—{min_w} (è£å‰ª)", "DEBUG")
        
        print(f"[SUCCESS] âœ… å·²å½’ä¸€åŒ– {len(normalized)} å¼ å›¾ç‰‡å°ºå¯¸")
        return normalized
    
    def _match_reference_size(self, output_tensors, input_images):
        """åŒ¹é…å‚è€ƒå›¾ç‰‡å°ºå¯¸ - ä½¿ç”¨ç¬¬ä¸€å¼ å‚è€ƒå›¾çš„å°ºå¯¸ä½œä¸ºç›®æ ‡"""
        if not output_tensors or not input_images:
            return output_tensors
        
        # è·å–ç¬¬ä¸€å¼ å‚è€ƒå›¾çš„å°ºå¯¸ (tensor shape: [H, W, C])
        ref_tensor = input_images[0]
        if len(ref_tensor.shape) > 3:
            ref_tensor = ref_tensor[0]  # å¦‚æœæ˜¯æ‰¹æ¬¡ï¼Œå–ç¬¬ä¸€å¼ 
        
        target_h = ref_tensor.shape[0]
        target_w = ref_tensor.shape[1]
        
        print(f"\n{'='*60}")
        print(f"[INFO] å¯ç”¨åŒ¹é…å‚è€ƒå°ºå¯¸åŠŸèƒ½")
        print(f"[INFO] å‚è€ƒå›¾å°ºå¯¸: {target_w}Ã—{target_h}")
        print(f"[INFO] å¾…å¤„ç†å›¾ç‰‡æ•°é‡: {len(output_tensors)}")
        print(f"{'='*60}\n")
        
        matched_tensors = []
        for idx, tensor in enumerate(output_tensors):
            current_h, current_w = tensor.shape[0], tensor.shape[1]
            
            if current_h == target_h and current_w == target_w:
                self.log(f"[DEBUG] å›¾ç‰‡{idx+1} å°ºå¯¸å·²åŒ¹é…ï¼Œè·³è¿‡è°ƒæ•´", "DEBUG")
                matched_tensors.append(tensor)
            else:
                print(f"[INFO] å›¾ç‰‡{idx+1}: {current_w}Ã—{current_h} â†’ {target_w}Ã—{target_h} (ç¼©æ”¾+è£å‰ª)")
                
                # è½¬æ¢ä¸º PIL Image
                array = (tensor.cpu().numpy() * 255.0).astype(np.uint8)
                pil_image = Image.fromarray(array, mode='RGB')
                
                # ä½¿ç”¨ ImageOps.fit è¿›è¡Œæ™ºèƒ½ç¼©æ”¾+å±…ä¸­è£å‰ª
                resized_image = ImageOps.fit(pil_image, (target_w, target_h), method=Image.LANCZOS)
                
                # è½¬å› tensor
                resized_array = np.array(resized_image).astype(np.float32) / 255.0
                resized_tensor = torch.from_numpy(resized_array)
                
                matched_tensors.append(resized_tensor)
        
        print(f"[SUCCESS] âœ… å·²å°† {len(matched_tensors)} å¼ å›¾ç‰‡è°ƒæ•´ä¸ºå‚è€ƒå°ºå¯¸ {target_w}Ã—{target_h}\n")
        return matched_tensors


# ComfyUI èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "NanoBananaNode": NanoBananaNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "NanoBananaNode": "artsmcp-nano-banana"
}

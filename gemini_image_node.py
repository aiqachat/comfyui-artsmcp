import base64
import configparser
import io
import json
from pathlib import Path
from typing import List, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed

import numpy as np
import requests
import torch
import urllib3
from PIL import Image

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

CATEGORY = "artsmcp"
CONFIG_SECTION = "Gemini-banana"  # ç‹¬ç«‹é…ç½®èŠ‚
CONFIG_PATH = Path(__file__).parent / "config.ini"
CONFIG = configparser.ConfigParser()
if CONFIG_PATH.exists():
    CONFIG.read(CONFIG_PATH, encoding="utf-8")
else:
    CONFIG[CONFIG_SECTION] = {}  # ä½¿ç”¨ç‹¬ç«‹é…ç½®èŠ‚
    with CONFIG_PATH.open("w", encoding="utf-8") as fp:
        CONFIG.write(fp)

# å›¾åƒå°ºå¯¸æ˜ å°„ï¼ˆGemini æ”¯æŒå¤šç§å®½é«˜æ¯”ï¼‰
IMAGE_SIZE_MAP = {
    "1:1": "1:1",
    "2:3": "2:3",
    "3:2": "3:2",
    "3:4": "3:4",
    "4:3": "4:3",
    "4:5": "4:5",
    "5:4": "5:4",
    "9:16": "9:16",
    "16:9": "16:9",
    "21:9": "21:9",
}

# æ¨¡å‹æ˜ å°„
MODEL_MAP = {
    "gemini-3-pro-image-preview": "gemini-3-pro-image-preview",
    "gemini-3-pro-image-preview-2k": "gemini-3-pro-image-preview-2k",
    "gemini-3-pro-image-preview-4k": "gemini-3-pro-image-preview-4k",
}

# å“åº”æ ¼å¼æ˜ å°„
RESPONSE_FORMAT_MAP = {
    "URL": "url",
    "Base64": "b64_json",
}


def tensor_to_base64(image_tensor):
    """å°† ComfyUI tensor è½¬æ¢ä¸º base64 å­—ç¬¦ä¸²"""
    if len(image_tensor.shape) > 3:
        image_tensor = image_tensor[0]
    
    array = np.clip(image_tensor.cpu().numpy() * 255.0, 0, 255).astype(np.uint8)
    pil_image = Image.fromarray(array, mode='RGB')
    
    buffered = io.BytesIO()
    pil_image.save(buffered, format="JPEG", quality=95)
    img_bytes = buffered.getvalue()
    base64_string = base64.b64encode(img_bytes).decode('utf-8')
    
    return f"data:image/jpeg;base64,{base64_string}"


def download_image_to_tensor(url: str, timeout: int = 60):
    """ä» URL ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸º tensor"""
    session = None
    response = None
    
    try:
        print(f"[INFO] æ­£åœ¨ä¸‹è½½å›¾ç‰‡: {url}")
        
        # ä½¿ç”¨ç‹¬ç«‹ Session
        session = requests.Session()
        response = session.get(url, timeout=timeout, verify=False, stream=True)
        response.raise_for_status()
        
        pil_image = Image.open(io.BytesIO(response.content)).convert('RGB')
        print(f"[INFO] å›¾ç‰‡å°ºå¯¸: {pil_image.size}")
        
        numpy_image = np.array(pil_image).astype(np.float32) / 255.0
        tensor = torch.from_numpy(numpy_image)
        
        return tensor
        
    except Exception as e:
        print(f"[ERROR] ä¸‹è½½å›¾ç‰‡å¤±è´¥: {e}")
        return None
        
    finally:
        # æ¸…ç†èµ„æº
        try:
            if response is not None:
                response.close()
            if session is not None:
                session.close()
        except Exception as e:
            print(f"[WARN] æ¸…ç†ä¸‹è½½è¿æ¥å¤±è´¥: {e}")


def base64_to_tensor(b64_string: str):
    """å°† base64 å­—ç¬¦ä¸²è½¬æ¢ä¸º tensor"""
    try:
        img_bytes = base64.b64decode(b64_string)
        pil_image = Image.open(io.BytesIO(img_bytes)).convert('RGB')
        numpy_image = np.array(pil_image).astype(np.float32) / 255.0
        tensor = torch.from_numpy(numpy_image)
        return tensor
    except Exception as e:
        print(f"[ERROR] Base64 è½¬æ¢å¤±è´¥: {e}")
        return None


def make_api_request(url: str, headers: dict, payload: dict, timeout: int = 120, max_retries: int = 3, backoff: int = 2):
    """å‘é€ API è¯·æ±‚ï¼ˆæ”¯æŒé‡è¯•ï¼‰"""
    import time
    
    # æ‰“å°è¯·æ±‚ä¿¡æ¯
    print(f"[INFO] å‘é€è¯·æ±‚åˆ°: {url}")
    print(f"[INFO] è¯·æ±‚å‚æ•°: {json.dumps(payload, ensure_ascii=False)[:200]}...")
    
    last_error = None
    
    for attempt in range(1, max_retries + 1):
        # å…³é”®ï¼šæ¯æ¬¡é‡è¯•éƒ½åˆ›å»ºæ–°çš„ Sessionï¼Œé¿å…è¿æ¥æ± æ±¡æŸ“
        session = requests.Session()
        response = None
        
        try:
            if attempt > 1:
                wait_time = min(backoff ** (attempt - 1), 20)  # æŒ‡æ•°é€€é¿: 2s, 4s, 8s, æœ€å¤§20s
                print(f"[INFO] ç¬¬ {attempt} æ¬¡é‡è¯•ï¼Œç­‰å¾… {wait_time} ç§’...")
                time.sleep(wait_time)
            
            response = session.post(
                url,
                headers=headers,
                json=payload,
                timeout=timeout,
                verify=False
            )
            
            # è¯¦ç»†çš„çŠ¶æ€ç å¤„ç†
            print(f"[INFO] HTTP çŠ¶æ€ç : {response.status_code}")
            
            # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
            response.raise_for_status()
            
            result = response.json()
            print(f"[SUCCESS] è¯·æ±‚æˆåŠŸï¼")
            print(f"[DEBUG] å®Œæ•´å“åº”æ•°æ®: {json.dumps(result, ensure_ascii=False, indent=2)}")
            
            # æˆåŠŸåå…³é—­
            response.close()
            session.close()
            return result
            
        except requests.exceptions.HTTPError as exc:
            last_error = exc
            print(f"[ERROR] HTTP é”™è¯¯ (å°è¯• {attempt}/{max_retries}): {exc}")
            
            # æ‰“å°å“åº”å†…å®¹ç”¨äºè°ƒè¯•
            try:
                if response is not None:
                    error_detail = response.json()
                    print(f"[ERROR] é”™è¯¯è¯¦æƒ…: {json.dumps(error_detail, ensure_ascii=False)}")
            except:
                if response is not None:
                    print(f"[ERROR] å“åº”æ–‡æœ¬: {response.text[:500]}")
            
            # 4xx å®¢æˆ·ç«¯é”™è¯¯ç›´æ¥æŠ›å‡ºï¼Œä¸é‡è¯•ï¼ˆé™¤äº† 429 é™æµï¼‰
            if 400 <= exc.response.status_code < 500 and exc.response.status_code != 429:
                print(f"[ERROR] å®¢æˆ·ç«¯é”™è¯¯ ({exc.response.status_code})ï¼Œä¸è¿›è¡Œé‡è¯•")
                # æ¸…ç†èµ„æº
                if response:
                    response.close()
                session.close()
                raise
                
        except requests.exceptions.Timeout as exc:
            last_error = exc
            print(f"[ERROR] è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt}/{max_retries}): {exc}")
            print(f"[DEBUG] è¶…æ—¶ç±»å‹: {type(exc).__name__}")
            
        except requests.exceptions.ConnectionError as exc:
            last_error = exc
            print(f"[ERROR] è¿æ¥å¤±è´¥ (å°è¯• {attempt}/{max_retries}): {exc}")
            
        except Exception as exc:
            last_error = exc
            print(f"[ERROR] æœªçŸ¥é”™è¯¯ (å°è¯• {attempt}/{max_retries}): {exc}")
        
        finally:
            # å…³é”®ï¼šæ— è®ºæˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œéƒ½å¿…é¡»æ¸…ç†èµ„æº
            try:
                if response is not None:
                    response.close()
                session.close()
            except Exception as e:
                print(f"[WARN] æ¸…ç†è¿æ¥å¤±è´¥: {e}")
        
        # å¦‚æœè¿˜æœ‰é‡è¯•æœºä¼šï¼Œç»§ç»­å¾ªç¯
        if attempt < max_retries:
            continue
    
    # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
    print(f"\n[ERROR] âŒ è¯·æ±‚æœ€ç»ˆå¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡")
    print(f"[ERROR] æœ€åé”™è¯¯: {last_error}")
    print(f"\nğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
    print(f"   1. æ£€æŸ¥ API æœåŠ¡æ˜¯å¦æ­£å¸¸: {url}")
    print(f"   2. ç¡®è®¤ API Key æ˜¯å¦æœ‰æ•ˆ")
    print(f"   3. ç¨åå†è¯•ï¼Œå¯èƒ½æ˜¯æœåŠ¡å™¨ä¸´æ—¶è¿‡è½½")
    print(f"   4. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦ç¨³å®š")
    print(f"   5. å°è¯•å¢åŠ  timeout å‚æ•°å€¼")
    
    if last_error:
        raise last_error
    raise RuntimeError("æœªçŸ¥è¯·æ±‚å¤±è´¥")


class GeminiBananaNode:
    """Gemini Banana å›¾ç‰‡ç”ŸæˆèŠ‚ç‚¹ - æ”¯æŒæ–‡ç”Ÿå›¾ã€å›¾ç”Ÿå›¾ã€å¤šå›¾èåˆ"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "æç¤ºè¯": ("STRING", {
                    "multiline": True,
                    "default": "æ˜Ÿé™…ç©¿è¶Š,é»‘æ´,ç”µå½±å¤§ç‰‡,è¶…ç°å®ä¸»ä¹‰",
                    "display": "input"
                }),
                "APIå¯†é’¥": ("STRING", {
                    "multiline": False,
                    "default": CONFIG.get(CONFIG_SECTION, "api_key", fallback="")
                }),
                "APIåœ°å€": ("STRING", {
                    "multiline": False,
                    "default": CONFIG.get(CONFIG_SECTION, "api_url", fallback="https://api.openai.com/v1/images/generations")
                }),
                "æ¨¡å‹": (list(MODEL_MAP.keys()), {
                    "default": list(MODEL_MAP.keys())[0]
                }),
                "å®½é«˜æ¯”": (list(IMAGE_SIZE_MAP.keys()), {
                    "default": "1:1"
                }),
                "å“åº”æ ¼å¼": (list(RESPONSE_FORMAT_MAP.keys()), {
                    "default": "URL"
                }),
                "è¶…æ—¶æ—¶é—´ç§’": ("INT", {
                    "default": 120,
                    "min": 30,
                    "max": 600,
                    "step": 10
                }),
                "æœ€å¤§é‡è¯•æ¬¡æ•°": ("INT", {
                    "default": 3,
                    "min": 1,
                    "max": 10,
                    "step": 1
                }),
                "å¯ç”¨åˆ†è¡Œæç¤ºè¯": ("BOOLEAN", {
                    "default": False
                }),
                "æ¯è¡Œå¹¶å‘è¯·æ±‚æ•°": ("INT", {
                    "default": 1,
                    "min": 1,
                    "max": 10,
                    "step": 1
                }),
            },
            "optional": {
                "å‚è€ƒå›¾ç‰‡1": ("IMAGE", {}),
                "å‚è€ƒå›¾ç‰‡2": ("IMAGE", {}),
                "å‚è€ƒå›¾ç‰‡3": ("IMAGE", {}),
                "å‚è€ƒå›¾ç‰‡4": ("IMAGE", {}),
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("å›¾ç‰‡è¾“å‡º",)
    FUNCTION = "generate_image"
    CATEGORY = CATEGORY
    OUTPUT_NODE = False  # æ ‡æ˜è¿™ä¸æ˜¯è¾“å‡ºèŠ‚ç‚¹
    
    @classmethod
    def IS_CHANGED(cls, **kwargs):
        """å¼ºåˆ¶æ¯æ¬¡éƒ½é‡æ–°æ‰§è¡Œ,ä¸ä½¿ç”¨ç¼“å­˜(å› ä¸ºæ˜¯å¤–éƒ¨APIè¯·æ±‚)"""
        import time
        return time.time()
    
    def generate_image(self, æç¤ºè¯, å¯ç”¨åˆ†è¡Œæç¤ºè¯, æ¯è¡Œå¹¶å‘è¯·æ±‚æ•°, 
                       APIå¯†é’¥, APIåœ°å€, æ¨¡å‹, å®½é«˜æ¯”, 
                       å“åº”æ ¼å¼, è¶…æ—¶æ—¶é—´ç§’, æœ€å¤§é‡è¯•æ¬¡æ•°,
                       å‚è€ƒå›¾ç‰‡1=None, å‚è€ƒå›¾ç‰‡2=None, å‚è€ƒå›¾ç‰‡3=None, å‚è€ƒå›¾ç‰‡4=None):
        """ä¸»ç”Ÿæˆå‡½æ•°"""
        
        # é‡å‘½åå˜é‡ä»¥ä¾¿å†…éƒ¨ä½¿ç”¨
        prompt = æç¤ºè¯
        enable_multiline = å¯ç”¨åˆ†è¡Œæç¤ºè¯
        concurrent_requests = æ¯è¡Œå¹¶å‘è¯·æ±‚æ•°
        api_key = APIå¯†é’¥
        base_url = APIåœ°å€
        model = æ¨¡å‹
        size = å®½é«˜æ¯”
        response_format = å“åº”æ ¼å¼
        timeout = è¶…æ—¶æ—¶é—´ç§’
        max_retries = æœ€å¤§é‡è¯•æ¬¡æ•°
        image1 = å‚è€ƒå›¾ç‰‡1
        image2 = å‚è€ƒå›¾ç‰‡2
        image3 = å‚è€ƒå›¾ç‰‡3
        image4 = å‚è€ƒå›¾ç‰‡4
        
        # ä¿å­˜é…ç½®åˆ°ç‹¬ç«‹é…ç½®èŠ‚
        if not CONFIG.has_section(CONFIG_SECTION):
            CONFIG.add_section(CONFIG_SECTION)
        
        if api_key.strip():
            CONFIG.set(CONFIG_SECTION, "api_key", api_key.strip())
        if base_url.strip():
            CONFIG.set(CONFIG_SECTION, "api_url", base_url.strip())
        
        with CONFIG_PATH.open("w", encoding="utf-8") as fp:
            CONFIG.write(fp)
        
        # å¤„ç†æç¤ºè¯æ‹†åˆ†
        prompts = []
        if enable_multiline:
            # æŒ‰è¡Œæ‹†åˆ†æç¤ºè¯ï¼Œè¿‡æ»¤ç©ºè¡Œ
            prompts = [line.strip() for line in prompt.split('\n') if line.strip()]
            print("\n" + "="*60)
            print("[Gemini-Banana] å¯ç”¨åˆ†è¡Œæç¤ºè¯æ¨¡å¼")
            print(f"  - æ‹†åˆ†åæç¤ºè¯æ•°é‡: {len(prompts)}")
            print(f"  - æ¯è¡Œå¹¶å‘è¯·æ±‚æ•°: {concurrent_requests}")
            print(f"  - æ€»ä»»åŠ¡æ•°: {len(prompts)} è¡Œ Ã— {concurrent_requests} å¹¶å‘ = {len(prompts) * concurrent_requests} å¼ å›¾")
            for idx, p in enumerate(prompts, 1):
                print(f"  - æç¤ºè¯{idx}: {p[:50]}...")
            print("="*60 + "\n")
        else:
            # å®Œæ•´æç¤ºè¯
            prompts = [prompt]
            print("\n" + "="*60)
            print("[Gemini-Banana] å®Œæ•´æç¤ºè¯æ¨¡å¼")
            print(f"  - æç¤ºè¯: {prompt[:50]}...")
            print(f"  - å¹¶å‘è¯·æ±‚æ•°: {concurrent_requests}")
            print(f"  - æ€»ä»»åŠ¡æ•°: {concurrent_requests} å¼ å›¾")
            print("="*60 + "\n")
        
        # æ‰“å°å…¶ä»–å‚æ•°
        print(f"[INFO] æ¨¡å‹: {model}")
        print(f"[INFO] å°ºå¯¸: {size}")
        print(f"[INFO] å“åº”æ ¼å¼: {response_format}")
        print(f"[INFO] è¶…æ—¶æ—¶é—´: {timeout}ç§’")
        print(f"[INFO] æœ€å¤§é‡è¯•æ¬¡æ•°: {max_retries}")
        
        # æ”¶é›†è¾“å…¥å›¾ç‰‡
        input_images = []
        for img in [image1, image2, image3, image4]:
            if img is not None:
                input_images.append(img)
        
        # å‡†å¤‡è¯·æ±‚åŸºç¡€å‚æ•°
        model_value = MODEL_MAP[model]
        size_value = IMAGE_SIZE_MAP[size]
        response_format_value = RESPONSE_FORMAT_MAP[response_format]
        
        # å¤„ç†è¾“å…¥å›¾ç‰‡è½¬ Base64ï¼ˆå¦‚æœæœ‰ï¼‰
        image_urls = []
        if input_images:
            for idx, img_tensor in enumerate(input_images):
                base64_url = tensor_to_base64(img_tensor)
                image_urls.append(base64_url)
                print(f"[INFO] å·²è½¬æ¢å›¾ç‰‡{idx + 1}ä¸º Base64")
        
        # å‡†å¤‡è¯·æ±‚å¤´
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        # æ‰¹é‡å‘é€è¯·æ±‚ï¼ˆçœŸæ­£çš„å¹¶å‘æ‰§è¡Œï¼‰
        print(f"\n{'='*60}")
        print(f"[INFO] å¼€å§‹å¹¶å‘å‘é€è¯·æ±‚...")
        print(f"[INFO] æç¤ºè¯æ•°é‡: {len(prompts)}")
        print(f"[INFO] æ¯è¡Œå¹¶å‘æ•°: {concurrent_requests}")
        print(f"[INFO] æ€»è¯·æ±‚ä»»åŠ¡æ•°: {len(prompts)}")
        print(f"[INFO] é¢„è®¡ç”Ÿæˆå›¾ç‰‡æ•°: {len(prompts) * concurrent_requests}")
        print(f"{'='*60}\n")
        
        # å‡†å¤‡æ‰€æœ‰è¯·æ±‚ä»»åŠ¡
        request_tasks = []
        for prompt_idx, current_prompt in enumerate(prompts, 1):
            # æ„å»ºå½“å‰æç¤ºè¯çš„è¯·æ±‚å‚æ•°
            payload = {
                "model": model_value,
                "prompt": current_prompt,
                "size": size_value,
                "response_format": response_format_value,
                "n": concurrent_requests,  # æ¯è¡Œçš„å¹¶å‘è¯·æ±‚æ•°
            }
            
            # æ·»åŠ å›¾ç‰‡ï¼ˆå¦‚æœæœ‰ï¼‰
            if image_urls:
                if len(image_urls) == 1:
                    payload["image"] = image_urls[0]
                else:
                    payload["image"] = image_urls
            
            request_tasks.append({
                "task_id": prompt_idx,
                "prompt": current_prompt,
                "payload": payload
            })
            
            print(f"[DEBUG] ä»»åŠ¡ {prompt_idx} - æç¤ºè¯: {current_prompt[:50]}...")
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å‘é€æ‰€æœ‰è¯·æ±‚
        all_results = []
        
        def send_single_request(task):
            """å‘é€å•ä¸ªè¯·æ±‚çš„å‡½æ•°"""
            task_id = task["task_id"]
            task_prompt = task["prompt"]
            task_payload = task["payload"]
            
            print(f"\n[INFO] â–¶ ä»»åŠ¡ {task_id} å¼€å§‹è¯·æ±‚: {task_prompt[:30]}...")
            
            try:
                result = make_api_request(base_url, headers, task_payload, timeout, max_retries)
                print(f"[SUCCESS] âœ… ä»»åŠ¡ {task_id} è¯·æ±‚æˆåŠŸ")
                return {
                    "task_id": task_id,
                    "prompt": task_prompt,
                    "result": result,
                    "success": True
                }
            except Exception as e:
                print(f"[ERROR] âŒ ä»»åŠ¡ {task_id} è¯·æ±‚å¤±è´¥: {e}")
                return {
                    "task_id": task_id,
                    "prompt": task_prompt,
                    "error": str(e),
                    "success": False
                }
        
        try:
            # åˆ›å»ºçº¿ç¨‹æ± ï¼Œæœ€å¤§å¹¶å‘æ•°ä¸ºæç¤ºè¯æ•°é‡ï¼ˆä½†ä¸è¶…è¿‡10ï¼‰
            max_workers = min(len(request_tasks), 10)
            print(f"\n[INFO] ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘æ‰§è¡Œï¼Œæœ€å¤§å¹¶å‘æ•°: {max_workers}")
            
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                future_to_task = {executor.submit(send_single_request, task): task for task in request_tasks}
                
                # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                for future in as_completed(future_to_task):
                    task_result = future.result()
                    all_results.append(task_result)
            
            print(f"\n{'='*60}")
            print(f"[INFO] æ‰€æœ‰è¯·æ±‚å·²å®Œæˆï¼")
            print(f"[INFO] æˆåŠŸ: {sum(1 for r in all_results if r['success'])} ä¸ª")
            print(f"[INFO] å¤±è´¥: {sum(1 for r in all_results if not r['success'])} ä¸ª")
            print(f"{'='*60}\n")
            
            # æŒ‰ä»»åŠ¡IDæ’åºï¼Œä¿æŒé¡ºåº
            all_results.sort(key=lambda x: x["task_id"])
            
            # ç»Ÿä¸€è§£ææ‰€æœ‰æˆåŠŸçš„å“åº”å¹¶å¹¶å‘ä¸‹è½½å›¾ç‰‡
            print(f"\n{'='*60}")
            print(f"[INFO] å¼€å§‹ç»Ÿä¸€è§£æå“åº”å¹¶å¹¶å‘ä¸‹è½½å›¾ç‰‡...")
            print(f"{'='*60}\n")
            
            # æ”¶é›†æ‰€æœ‰éœ€è¦ä¸‹è½½çš„å›¾ç‰‡ä»»åŠ¡
            download_tasks = []
            
            for task_result in all_results:
                if not task_result["success"]:
                    print(f"[WARN] âš  è·³è¿‡å¤±è´¥çš„ä»»åŠ¡ {task_result['task_id']}: {task_result.get('error', 'Unknown')}")
                    continue
                
                result = task_result["result"]
                task_id = task_result["task_id"]
                task_prompt = task_result["prompt"]
                
                print(f"\n[INFO] è§£æä»»åŠ¡ {task_id} çš„å“åº” - æç¤ºè¯: {task_prompt[:30]}...")
                print(f"[DEBUG] å“åº”åŒ…å«çš„é”®: {list(result.keys())}")
                
                if "data" in result:
                    data = result["data"]
                    print(f"[DEBUG] data ç±»å‹: {type(data)}")
                                
                    if isinstance(data, list):
                        print(f"[DEBUG] data æ˜¯åˆ—è¡¨ï¼Œé•¿åº¦: {len(data)}")
                        for idx, item in enumerate(data, 1):
                            print(f"[DEBUG] å‡†å¤‡ä¸‹è½½ä»»åŠ¡ {task_id} çš„ç¬¬ {idx}/{len(data)} å¼ å›¾ç‰‡")
                            print(f"[DEBUG] å›¾ç‰‡é¡¹åŒ…å«çš„é”®: {list(item.keys()) if isinstance(item, dict) else 'N/A'}")
                            
                            download_tasks.append({
                                "task_id": task_id,
                                "image_idx": idx,
                                "item": item,
                                "order": len(download_tasks)  # ç”¨äºä¿æŒé¡ºåº
                            })
                                            
                    elif isinstance(data, dict):
                        print(f"[DEBUG] data æ˜¯å­—å…¸")
                        print(f"[DEBUG] å­—å…¸åŒ…å«çš„é”®: {list(data.keys())}")
                        
                        download_tasks.append({
                            "task_id": task_id,
                            "image_idx": 1,
                            "item": data,
                            "order": len(download_tasks)
                        })
                else:
                    print(f"[ERROR] ä»»åŠ¡ {task_id} å“åº”ä¸­æ²¡æœ‰ 'data' å­—æ®µï¼")
                    print(f"[DEBUG] å®Œæ•´å“åº”å†…å®¹: {result}")
                                
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å›¾åƒåˆ†æAPIçš„å“åº”æ ¼å¼
                    if "created" in result and "usage" in result:
                        print(f"[INFO] æ£€æµ‹åˆ°å¯èƒ½æ˜¯å›¾åƒåˆ†æAPIçš„å“åº”ï¼Œæ²¡æœ‰å›¾ç‰‡æ•°æ®")
            
            # å¹¶å‘ä¸‹è½½æ‰€æœ‰å›¾ç‰‡
            if not download_tasks:
                print("[ERROR] âŒ æ²¡æœ‰å¯ä¸‹è½½çš„å›¾ç‰‡ä»»åŠ¡ï¼")
                print("[WARN] è¿”å›é»˜è®¤é»‘è‰²å›¾ç‰‡")
                return (torch.zeros((1, 512, 512, 3)),)
            
            print(f"\n{'='*60}")
            print(f"[INFO] å¼€å§‹å¹¶å‘ä¸‹è½½ {len(download_tasks)} å¼ å›¾ç‰‡...")
            print(f"{'='*60}\n")
            
            def download_single_image(task):
                """ä¸‹è½½å•å¼ å›¾ç‰‡çš„å‡½æ•°"""
                task_id = task["task_id"]
                image_idx = task["image_idx"]
                item = task["item"]
                order = task["order"]
                
                print(f"[INFO] â–¶ å¼€å§‹ä¸‹è½½ä»»åŠ¡ {task_id} çš„ç¬¬ {image_idx} å¼ å›¾ç‰‡...")
                
                try:
                    tensor = self._process_image_item(item, response_format_value, timeout)
                    if tensor is not None:
                        print(f"[SUCCESS] âœ… ä»»åŠ¡ {task_id} ç¬¬ {image_idx} å¼ å›¾ç‰‡ä¸‹è½½æˆåŠŸ")
                        return {
                            "order": order,
                            "task_id": task_id,
                            "image_idx": image_idx,
                            "tensor": tensor,
                            "success": True
                        }
                    else:
                        print(f"[ERROR] âŒ ä»»åŠ¡ {task_id} ç¬¬ {image_idx} å¼ å›¾ç‰‡ä¸‹è½½å¤±è´¥")
                        return {
                            "order": order,
                            "task_id": task_id,
                            "image_idx": image_idx,
                            "success": False
                        }
                except Exception as e:
                    print(f"[ERROR] âŒ ä»»åŠ¡ {task_id} ç¬¬ {image_idx} å¼ å›¾ç‰‡ä¸‹è½½å¼‚å¸¸: {e}")
                    return {
                        "order": order,
                        "task_id": task_id,
                        "image_idx": image_idx,
                        "success": False,
                        "error": str(e)
                    }
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘ä¸‹è½½
            download_results = []
            max_download_workers = min(len(download_tasks), 10)
            print(f"[INFO] ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘ä¸‹è½½ï¼Œæœ€å¤§å¹¶å‘æ•°: {max_download_workers}\n")
            
            with ThreadPoolExecutor(max_workers=max_download_workers) as executor:
                future_to_download = {executor.submit(download_single_image, task): task for task in download_tasks}
                
                for future in as_completed(future_to_download):
                    result = future.result()
                    download_results.append(result)
            
            # æŒ‰orderæ’åºï¼Œä¿æŒåŸå§‹é¡ºåº
            download_results.sort(key=lambda x: x["order"])
            
            # æå–æˆåŠŸä¸‹è½½çš„tensor
            output_tensors = []
            for result in download_results:
                if result["success"]:
                    output_tensors.append(result["tensor"])
            
            print(f"\n{'='*60}")
            print(f"[INFO] ä¸‹è½½å®Œæˆç»Ÿè®¡")
            print(f"[INFO] æˆåŠŸ: {len(output_tensors)} å¼ ")
            print(f"[INFO] å¤±è´¥: {len(download_results) - len(output_tensors)} å¼ ")
            print(f"{'='*60}\n")
                        
            if not output_tensors:
                print("[ERROR] âŒ æœªè·å–åˆ°ä»»ä½•å›¾ç‰‡æ•°æ®ï¼")
                print(f"[DEBUG] è¾“å‡º tensors æ•°é‡: {len(output_tensors)}")
                print("[WARN] è¿”å›é»˜è®¤é»‘è‰²å›¾ç‰‡")
                return (torch.zeros((1, 512, 512, 3)),)
            
            # åˆå¹¶æ‰€æœ‰ tensor
            batch_tensor = torch.stack(output_tensors, dim=0)
            print(f"\n{'='*60}")
            print(f"[SUCCESS] âœ… æˆåŠŸç”Ÿæˆ {len(output_tensors)} å¼ å›¾ç‰‡!")
            print(f"[INFO] æ‰¹æ¬¡å°ºå¯¸: {batch_tensor.shape}")
            if enable_multiline:
                print(f"[INFO] æç¤ºè¯æ•°é‡: {len(prompts)} è¡Œ")
                print(f"[INFO] æ¯è¡Œå¹¶å‘æ•°: {concurrent_requests}")
                print(f"[INFO] æ€»å›¾ç‰‡æ•°: {len(prompts)} Ã— {concurrent_requests} = {len(output_tensors)}")
            else:
                print(f"[INFO] å¹¶å‘è¯·æ±‚æ•°: {concurrent_requests}")
            print(f"{'='*60}\n")
            
            print(f"[DEBUG] å‡†å¤‡è¿”å› tensorï¼Œç¡®ä¿æ•°æ®å®Œæ•´æ€§...")
            print(f"[DEBUG] tensor ç±»å‹: {type(batch_tensor)}")
            print(f"[DEBUG] tensor device: {batch_tensor.device}")
            print(f"[DEBUG] tensor dtype: {batch_tensor.dtype}")
            
            # æ‰“å°è¯¦ç»†çš„è¾“å‡ºæ•°æ®ä¿¡æ¯
            print(f"\n{'='*60}")
            print(f"[OUTPUT] å‡†å¤‡ä¼ é€’ç»™ä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„æ•°æ®è¯¦æƒ…:")
            print(f"{'='*60}")
            print(f"[OUTPUT] æ•°æ®ç±»å‹: {type(batch_tensor).__name__}")
            print(f"[OUTPUT] æ•°æ®å½¢çŠ¶ (shape): {batch_tensor.shape}")
            print(f"  â”œâ”€ æ‰¹æ¬¡å¤§å° (batch): {batch_tensor.shape[0]}")
            print(f"  â”œâ”€ å›¾ç‰‡é«˜åº¦ (height): {batch_tensor.shape[1]}")
            print(f"  â”œâ”€ å›¾ç‰‡å®½åº¦ (width): {batch_tensor.shape[2]}")
            print(f"  â””â”€ é€šé“æ•° (channels): {batch_tensor.shape[3]}")
            print(f"[OUTPUT] æ•°æ®ç»´åº¦ (ndim): {batch_tensor.ndim}")
            print(f"[OUTPUT] å…ƒç´ æ€»æ•°: {batch_tensor.numel():,}")
            print(f"[OUTPUT] æ•°æ®ç±»å‹ (dtype): {batch_tensor.dtype}")
            print(f"[OUTPUT] å­˜å‚¨è®¾å¤‡ (device): {batch_tensor.device}")
            print(f"[OUTPUT] æ˜¯å¦éœ€è¦æ¢¯åº¦: {batch_tensor.requires_grad}")
            print(f"[OUTPUT] å†…å­˜å¤§å°: {batch_tensor.element_size() * batch_tensor.numel() / 1024 / 1024:.2f} MB")
            print(f"[OUTPUT] æ•°å€¼èŒƒå›´: [{batch_tensor.min():.4f}, {batch_tensor.max():.4f}]")
            print(f"[OUTPUT] æ•°å€¼å‡å€¼: {batch_tensor.mean():.4f}")
            print(f"[OUTPUT] æ•°å€¼æ ‡å‡†å·®: {batch_tensor.std():.4f}")
            
            # æ‰“å°æ¯å¼ å›¾ç‰‡çš„è¯¦ç»†ä¿¡æ¯
            if batch_tensor.shape[0] <= 5:  # åªåœ¨å›¾ç‰‡æ•°é‡ä¸å¤šæ—¶æ‰“å°è¯¦ç»†ä¿¡æ¯
                print(f"\n[OUTPUT] å„å›¾ç‰‡è¯¦ç»†ä¿¡æ¯:")
                for i in range(batch_tensor.shape[0]):
                    img_tensor = batch_tensor[i]
                    print(f"  å›¾ç‰‡ {i+1}:")
                    print(f"    â”œâ”€ å°ºå¯¸: {img_tensor.shape[1]}Ã—{img_tensor.shape[0]} ({img_tensor.shape[2]} é€šé“)")
                    print(f"    â”œâ”€ æ•°å€¼èŒƒå›´: [{img_tensor.min():.4f}, {img_tensor.max():.4f}]")
                    print(f"    â”œâ”€ å‡å€¼: {img_tensor.mean():.4f}")
                    print(f"    â””â”€ æ ‡å‡†å·®: {img_tensor.std():.4f}")
            
            print(f"\n[OUTPUT] è¿”å›å€¼ç»“æ„: tuple åŒ…å« 1 ä¸ªå…ƒç´ ")
            print(f"[OUTPUT] è¿”å›å€¼å†…å®¹: (torch.Tensor,)")
            print(f"[OUTPUT] ComfyUI å°†æ¥æ”¶åˆ°ç±»å‹ä¸º 'IMAGE' çš„è¾“å‡º")
            print(f"{'='*60}\n")
            
            print(f"[INFO] âœ… èŠ‚ç‚¹æ‰§è¡Œå®Œæ¯•ï¼Œè¿”å›ç»“æœ")
            
            # ç›´æ¥è¿”å›ï¼Œä¸åšä»»ä½•é¢å¤–æ“ä½œ
            return (batch_tensor,)
            
        except Exception as e:
            # æ‰€æœ‰å¼‚å¸¸ç»Ÿä¸€å¤„ç†ï¼Œç›´æ¥å‘ä¸Šä¼ é€’
            print(f"[ERROR] ç”Ÿæˆå¤±è´¥: {e}")
            print(f"[DEBUG] å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            import traceback
            traceback.print_exc()
            raise
    
    def _process_image_item(self, item: dict, format_type: str, timeout: int):
        """å¤„ç†å•ä¸ªå›¾ç‰‡æ•°æ®é¡¹"""
        print(f"[DEBUG] _process_image_item è°ƒç”¨: format_type={format_type}")
        print(f"[DEBUG] item å†…å®¹: {item}")
        
        if format_type == "url" and "url" in item:
            print(f"[DEBUG] åŒ¹é…åˆ° URL æ ¼å¼ï¼Œå¼€å§‹ä¸‹è½½...")
            return download_image_to_tensor(item["url"], timeout)
        elif format_type == "b64_json" and "b64_json" in item:
            print(f"[DEBUG] åŒ¹é…åˆ° Base64 æ ¼å¼ï¼Œå¼€å§‹è§£ç ...")
            return base64_to_tensor(item["b64_json"])
        else:
            print(f"[ERROR] æœªåŒ¹é…åˆ°ä»»ä½•æ ¼å¼ï¼")
            print(f"[DEBUG] æœŸæœ›æ ¼å¼: {format_type}")
            print(f"[DEBUG] item åŒ…å«çš„é”®: {list(item.keys()) if isinstance(item, dict) else 'N/A'}")
            return None


# ComfyUI èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "GeminiBananaNode": GeminiBananaNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "GeminiBananaNode": "artsmcp-gemini-banana"
}
